{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "52e460fe-1116-44a9-858c-b73b18d78407",
   "metadata": {},
   "source": [
    "# Agno Assist Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6d9b3b32-0d9e-43ba-bbb7-18dc4675cd33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000080; text-decoration-color: #000080\">INFO</span> Creating collection                                                                                           \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[34mINFO\u001b[0m Creating collection                                                                                           \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000080; text-decoration-color: #000080\">INFO</span> Loading knowledge base                                                                                        \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[34mINFO\u001b[0m Loading knowledge base                                                                                        \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000080; text-decoration-color: #000080\">INFO</span> Added <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">408</span> documents to knowledge base                                                                         \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[34mINFO\u001b[0m Added \u001b[1;36m408\u001b[0m documents to knowledge base                                                                         \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-28 18:58:36.398 WARNING streamlit.runtime.scriptrunner_utils.script_run_context: Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-06-28 18:58:36.480 \n",
      "  \u001b[33m\u001b[1mWarning:\u001b[0m to view this Streamlit app on a browser, run it with the following\n",
      "  command:\n",
      "\n",
      "    streamlit run /opt/anaconda3/envs/local_llm/lib/python3.12/site-packages/ipykernel_launcher.py [ARGUMENTS]\n",
      "2025-06-28 18:58:36.480 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-06-28 18:58:36.480 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-06-28 18:58:36.481 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-06-28 18:58:36.481 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-06-28 18:58:36.481 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-06-28 18:58:36.481 Session state does not function when running a script without `streamlit run`\n",
      "2025-06-28 18:58:36.481 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-06-28 18:58:36.482 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n"
     ]
    }
   ],
   "source": [
    "from textwrap import dedent\n",
    "from typing import Optional\n",
    "\n",
    "from agno.agent import Agent, AgentKnowledge, RunResponse\n",
    "from agno.knowledge.url import UrlKnowledge\n",
    "from agno.memory.v2.memory import Memory\n",
    "from agno.tools.duckduckgo import DuckDuckGoTools\n",
    "\n",
    "from agno.models.ollama import Ollama\n",
    "from agno.embedder.ollama import OllamaEmbedder\n",
    "from agno.knowledge.pdf import PDFKnowledgeBase, PDFReader\n",
    "from agno.vectordb.chroma import ChromaDb\n",
    "import asyncio\n",
    "from typing import Iterator\n",
    "from textwrap import dedent\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "import tempfile\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "knowledge_base = UrlKnowledge(\n",
    "        urls=[\"https://docs.agno.com/llms-full.txt\"],\n",
    "        vector_db= ChromaDb(collection=\"agno_assist_knowledge\",embedder=OllamaEmbedder(id = \"snowflake-arctic-embed2\", dimensions=1024)),\n",
    "        )\n",
    "    \n",
    "knowledge_base.load(recreate=False)\n",
    "\n",
    "\n",
    "model = Ollama(\"deepseek-coder-v2:16b\")\n",
    "user_id: Optional[str] = None\n",
    "session_id: Optional[str] = None\n",
    "debug_mode: bool = True\n",
    "\n",
    "agent =  Agent(\n",
    "        name=\"Agno Assist\",\n",
    "        agent_id=\"agno_assist\",\n",
    "        user_id=user_id,\n",
    "        session_id=session_id,\n",
    "        model=model,\n",
    "        # Tools available to the agent\n",
    "        tools=[DuckDuckGoTools()],\n",
    "        # Description of the agent\n",
    "        description=dedent(\"\"\"\\\n",
    "            You are AgnoAssist, an advanced AI Agent specializing in Agno: a lightweight framework for building multi-modal, reasoning Agents.\n",
    "\n",
    "            Your goal is to help developers understand and use Agno by providing clear explanations, functional code examples, and best-practice guidance for using Agno.\n",
    "        \"\"\"),\n",
    "        # Instructions for the agent\n",
    "        instructions=dedent(\"\"\"\\\n",
    "            Your mission is to provide comprehensive and actionable support for developers working with the Agno framework. Follow these steps to deliver high-quality assistance:\n",
    "\n",
    "            1. **Understand the request**\n",
    "            - Analyze the request to determine if it requires a knowledge search, creating an Agent, or both.\n",
    "            - If you need to search the knowledge base, identify 1-3 key search terms related to Agno concepts.\n",
    "            - If you need to create an Agent, search the knowledge base for relevant concepts and use the example code as a guide.\n",
    "            - When the user asks for an Agent, they mean an Agno Agent.\n",
    "            - All concepts are related to Agno, so you can search the knowledge base for relevant information\n",
    "\n",
    "            After Analysis, always start the iterative search process. No need to wait for approval from the user.\n",
    "\n",
    "            2. **Iterative Knowledge Base Search:**\n",
    "            - Use the `search_knowledge_base` tool to iteratively gather information.\n",
    "            - Focus on retrieving Agno concepts, illustrative code examples, and specific implementation details relevant to the user's request.\n",
    "            - Continue searching until you have sufficient information to comprehensively address the query or have explored all relevant search terms.\n",
    "\n",
    "            After the iterative search process, determine if you need to create an Agent.\n",
    "\n",
    "            3. **Code Creation**\n",
    "            - Create complete, working code examples that users can run. For example:\n",
    "            ```python\n",
    "            from agno.agent import Agent\n",
    "            from agno.tools.duckduckgo import DuckDuckGoTools\n",
    "\n",
    "            agent = Agent(tools=[DuckDuckGoTools()])\n",
    "\n",
    "            # Perform a web search and capture the response\n",
    "            response = agent.run(\"What's happening in France?\")\n",
    "            ```\n",
    "            - Remember to:\n",
    "                * Build the complete agent implementation\n",
    "                * Includes all necessary imports and setup\n",
    "                * Add comprehensive comments explaining the implementation\n",
    "                * Ensure all dependencies are listed\n",
    "                * Include error handling and best practices\n",
    "                * Add type hints and documentation\n",
    "\n",
    "            Key topics to cover:\n",
    "            - Agent architecture, levels, and capabilities.\n",
    "            - Knowledge base integration and memory management strategies.\n",
    "            - Tool creation, integration, and usage.\n",
    "            - Supported models and their configuration.\n",
    "            - Common development patterns and best practices within Agno.\n",
    "\n",
    "            Additional Information:\n",
    "            - You are interacting with the user_id: {current_user_id}\n",
    "            - The user's name might be different from the user_id, you may ask for it if needed and add it to your memory if they share it with you.\\\n",
    "        \"\"\"),\n",
    "        # This makes `current_user_id` available in the instructions\n",
    "        add_state_in_messages=True,\n",
    "        # -*- Knowledge -*-\n",
    "        # Add the knowledge base to the agent\n",
    "        knowledge=knowledge_base,\n",
    "        # Give the agent a tool to search the knowledge base (this is True by default but set here for clarity)\n",
    "        search_knowledge=True,\n",
    "        # -*- Storage -*-\n",
    "        # Storage chat history and session state in a Postgres table\n",
    "        # storage=PostgresAgentStorage(table_name=\"agno_assist_sessions\", db_url=db_url),\n",
    "        # -*- History -*-\n",
    "        # Send the last 3 messages from the chat history\n",
    "        add_history_to_messages=True,\n",
    "        num_history_runs=3,\n",
    "        # Add a tool to read the chat history if needed\n",
    "        read_chat_history=True,\n",
    "        # -*- Memory -*-\n",
    "        # Enable agentic memory where the Agent can personalize responses to the user\n",
    "        #memory=Memory(\n",
    "            #model=Ollama(\"deepseek-coder-v2:16b\"),\n",
    "            #db=PostgresMemoryDb(table_name=\"user_memories\", db_url=db_url),\n",
    "            #delete_memories=True,\n",
    "            #clear_memories=True,\n",
    "        #),\n",
    "        enable_agentic_memory=True,\n",
    "        # -*- Other settings -*-\n",
    "        # Format responses using markdown\n",
    "        markdown=True,\n",
    "        # Add the current date and time to the instructions\n",
    "        add_datetime_to_instructions=True,\n",
    "        # Show debug logs\n",
    "        debug_mode=debug_mode,\n",
    "    )\n",
    "\n",
    "import streamlit as st\n",
    "\n",
    "\n",
    "# Streamlit setup\n",
    "st.title(\"Whitecurls, tu asesor legal\")\n",
    "prompt = st.text_input(\"En qué te puedo ayudar?\")\n",
    "\n",
    "\n",
    "# Generate display response \n",
    "\n",
    "if prompt:\n",
    "    with st.spinner(\"Buscando respuestas...\"):\n",
    "        stream = True\n",
    "        if stream:\n",
    "            knowledge_base.load(recreate=False)\n",
    "            run_response: Iterator[RunResponse] = agent.run(prompt, stream = True, knowledge = knowledge_base)\n",
    "            response = \"\"\n",
    "            text_placeholder = st.empty()\n",
    "            for chunk in run_response:\n",
    "                response += chunk.content\n",
    "                text_placeholder.markdown(response)\n",
    "                \n",
    "        else:\n",
    "            knowledge_base.load(recreate=False)\n",
    "            response = agent.run(prompt, stream = False)\n",
    "            response = response.content\n",
    "            st.write(response)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27ba45f8-8836-432d-bc34-aacfcabb1981",
   "metadata": {},
   "source": [
    "# GUI\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b53b36f-e239-4645-b140-5454c7db7076",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import streamlit as st\n",
    "\n",
    "\n",
    "# Streamlit setup\n",
    "st.title(\"Whitecurls, tu asesor legal\")\n",
    "prompt = st.text_input(\"En qué te puedo ayudar?\")\n",
    "\n",
    "\n",
    "# Generate display response \n",
    "\n",
    "if prompt:\n",
    "    with st.spinner(\"Buscando respuestas...\"):\n",
    "        stream = True\n",
    "        if stream:\n",
    "            knowledge_base.load(recreate=False)\n",
    "            run_response: Iterator[RunResponse] = agent.run(prompt, stream = True, knowledge = knowledge_base)\n",
    "            response = \"\"\n",
    "            text_placeholder = st.empty()\n",
    "            for chunk in run_response:\n",
    "                response += chunk.content\n",
    "                text_placeholder.markdown(response)\n",
    "                \n",
    "        else:\n",
    "            knowledge_base.load(recreate=False)\n",
    "            response = agent.run(prompt, stream = False)\n",
    "            response = response.content\n",
    "            st.write(response)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
